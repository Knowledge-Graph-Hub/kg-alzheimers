{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMC XML to Text Conversion\n",
    "\n",
    "This notebook documents the process of converting a set of PubMed Central (PMC) XML files representing a trusted corpus of curated papers from Don Elbert and collagues. We convert the XML files to plain text format, for use as RAG source.  \n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Input**: PMC XML files containing full-text research papers\n",
    "- **Output**: Plain text files with structured content (title, abstract, sections)\n",
    "- **Purpose**: Prepare text data for downstream processing, analysis, and knowledge extraction\n",
    "\n",
    "## Data Source\n",
    "\n",
    "The XML files are located in `data/alz_papers_3k/` and contain approximately 3,000 Alzheimer's disease related research papers from PubMed Central."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the project root to the path so we can import the conversion script\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Input Data\n",
    "\n",
    "First, let's verify the XML data is available and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "xml_data_dir = project_root / \"data\" / \"alz_papers_3k\"\n",
    "output_dir = project_root / \"data\" / \"alz_papers_3k_text\"\n",
    "\n",
    "print(f\"XML data directory: {xml_data_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"XML directory exists: {xml_data_dir.exists()}\")\n",
    "\n",
    "if xml_data_dir.exists():\n",
    "    # Count XML files\n",
    "    xml_files = list(xml_data_dir.rglob(\"*.xml\"))\n",
    "    print(f\"\\nFound {len(xml_files)} XML files\")\n",
    "    \n",
    "    # Show a few example filenames\n",
    "    print(\"\\nExample files:\")\n",
    "    for i, file in enumerate(xml_files[:5]):\n",
    "        print(f\"  {file.name}\")\n",
    "    \n",
    "    if len(xml_files) > 5:\n",
    "        print(f\"  ... and {len(xml_files) - 5} more\")\n",
    "else:\n",
    "    print(\"‚ùå XML data directory not found!\")\n",
    "    print(\"Please ensure the XML data is located at:\", xml_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Conversion Script\n",
    "\n",
    "Now we'll run the conversion script to transform XML files into text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Path to the conversion script\n",
    "script_path = project_root / \"scripts\" / \"convert_pmc_xml_to_text.py\"\n",
    "\n",
    "print(f\"Conversion script: {script_path}\")\n",
    "print(f\"Script exists: {script_path.exists()}\")\n",
    "\n",
    "if not script_path.exists():\n",
    "    print(\"‚ùå Conversion script not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record start time\n",
    "start_time = datetime.now()\n",
    "print(f\"Starting conversion at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Run the conversion script\n",
    "cmd = [\n",
    "    \"python\", \n",
    "    str(script_path),\n",
    "    str(xml_data_dir),\n",
    "    str(output_dir),\n",
    "    \"--verbose\"\n",
    "]\n",
    "\n",
    "print(f\"\\nRunning command: {' '.join(cmd)}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Execute the script and capture output\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=project_root,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=1800  # 30 minute timeout\n",
    "    )\n",
    "    \n",
    "    print(\"STDOUT:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\nSTDERR:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    print(f\"\\nReturn code: {result.returncode}\")\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚ùå Script timed out after 30 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running script: {e}\")\n",
    "\n",
    "# Record end time\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "print(f\"\\nConversion completed at: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total duration: {duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Output\n",
    "\n",
    "Let's check the results of the conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output directory\n",
    "if output_dir.exists():\n",
    "    text_files = list(output_dir.glob(\"*.txt\"))\n",
    "    print(f\"Created {len(text_files)} text files\")\n",
    "    \n",
    "    if text_files:\n",
    "        # Show some statistics\n",
    "        total_size = sum(f.stat().st_size for f in text_files)\n",
    "        avg_size = total_size / len(text_files) if text_files else 0\n",
    "        \n",
    "        print(f\"Total output size: {total_size / 1024 / 1024:.1f} MB\")\n",
    "        print(f\"Average file size: {avg_size / 1024:.1f} KB\")\n",
    "        \n",
    "        # Show example filenames\n",
    "        print(\"\\nExample output files:\")\n",
    "        for i, file in enumerate(sorted(text_files)[:5]):\n",
    "            size_kb = file.stat().st_size / 1024\n",
    "            print(f\"  {file.name} ({size_kb:.1f} KB)\")\n",
    "        \n",
    "        if len(text_files) > 5:\n",
    "            print(f\"  ... and {len(text_files) - 5} more\")\n",
    "    else:\n",
    "        print(\"‚ùå No text files created!\")\n",
    "else:\n",
    "    print(\"‚ùå Output directory not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Output\n",
    "\n",
    "Let's examine a sample converted text file to verify the quality of the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display a sample file\n",
    "if text_files:\n",
    "    sample_file = text_files[0]\n",
    "    print(f\"Sample file: {sample_file.name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Show first 2000 characters\n",
    "        preview_length = 2000\n",
    "        if len(content) > preview_length:\n",
    "            print(content[:preview_length])\n",
    "            print(f\"\\n... (showing first {preview_length} characters of {len(content)} total)\")\n",
    "        else:\n",
    "            print(content)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading sample file: {e}\")\n",
    "else:\n",
    "    print(\"No text files available to sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Summary\n",
    "\n",
    "Summary of the XML to text conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "print(\"üìä CONVERSION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Input directory: {xml_data_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "if 'xml_files' in locals():\n",
    "    print(f\"Input XML files: {len(xml_files)}\")\n",
    "else:\n",
    "    print(\"Input XML files: Not counted\")\n",
    "\n",
    "if 'text_files' in locals():\n",
    "    print(f\"Output text files: {len(text_files)}\")\n",
    "    if xml_files and text_files:\n",
    "        success_rate = len(text_files) / len(xml_files) * 100\n",
    "        print(f\"Success rate: {success_rate:.1f}%\")\n",
    "else:\n",
    "    print(\"Output text files: Not counted\")\n",
    "\n",
    "if 'duration' in locals():\n",
    "    print(f\"Processing time: {duration}\")\n",
    "\n",
    "print(\"\\n‚úÖ Conversion process completed!\")\n",
    "print(\"\\nThe converted text files are ready for:\")\n",
    "print(\"- Text analysis and NLP processing\")\n",
    "print(\"- Knowledge extraction\")\n",
    "print(\"- Integration into the knowledge graph pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "With the text files now available, you can:\n",
    "\n",
    "1. **Text Analysis**: Perform entity recognition, relationship extraction, etc.\n",
    "2. **Knowledge Extraction**: Extract facts and relationships for the knowledge graph\n",
    "3. **Quality Assessment**: Review conversion quality and identify any issues\n",
    "4. **Integration**: Incorporate the text data into your existing knowledge graph pipeline\n",
    "\n",
    "The converted text files maintain the structure of the original papers with clear section headers (Title, Abstract, Introduction, Methods, etc.) making them suitable for downstream processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
